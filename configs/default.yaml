name: random-fixed-lstm2-tflayer2-emb256-ffn128-dropout.1-8heads
generic:
  seed: 42
  log_dir: "log"
  clear_log: False
data:
  data_dir: './data/download/files/'
  csv_out: './train/data.csv'
  hard_csv_out: './train/data_hard.csv'
  remake_csv: False
  gen_hard_dataset: False
  batch_size: 16
  shuffle: True
  img_height: 128
  dataset_split: [.8, .1, .1]  # train, val, test
  vocab_path: './data/download/vocab.txt'
  max_chord_stack: 10
  max_seq_len: 2048
training:
  epochs: 500000
  save: True
  save_every: 1
  save_dir: "./saved_models/"
  decode: True
  decode_every: 1
encoder:
  layers: [2, 2, 2, 2]
  no_lstm_layers: 2
  lr: 1e-4
decoder:
  d_model: 256
  n_head: 8
  max_len: 400  # TODO check
  ffn_hidden: 128
  n_layers: 2
  drop_prob: 0.1
  lr: 1e-4